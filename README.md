# AI Core
<p align="center">
  <img src="assets/icon/logo.jpeg" alt="ai-core Logo" width="500"> <br/>
</p>

<p align="center">
  ‰∏Ä‰∏™È´òÂèØÊâ©Â±ïÁöÑ AI ÁÆóÊ≥ïÂ∫ì„ÄÇ
</p>

---
[English](README_EN.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README.md)
---

![Version](https://img.shields.io/badge/version-1.1.2-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![C++ Standard](https://img.shields.io/badge/C++-17-blue.svg)

**AI Core** ÊòØ‰∏Ä‰∏™Áé∞‰ª£Âåñ„ÄÅÈ´òÊÄßËÉΩ„ÄÅÂèØÊâ©Â±ïÁöÑ C++ AI Êé®ÁêÜÊ°ÜÊû∂„ÄÇÊó®Âú®ÁÆÄÂåñ AI Ê®°ÂûãÂú®Â§öÁßçÁ°¨‰ª∂ÂêéÁ´Ø‰∏äÁöÑÈÉ®ÁΩ≤ÊµÅÁ®ãÔºåÊèê‰æõ‰ªéÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ„ÄÅÊ®°ÂûãÊé®ÁêÜÂà∞ÁªìÊûúÂêéÂ§ÑÁêÜÁöÑÁ´ØÂà∞Á´ØËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## Ê†∏ÂøÉÁâπÊÄß

*   **üì¶ Ê®°ÂùóÂåñÊµÅÁ®ã (Modular Pipeline):** ÈááÁî® **È¢ÑÂ§ÑÁêÜ -> Êé®ÁêÜ -> ÂêéÂ§ÑÁêÜ** ‰∏âÊÆµÂºèÊµÅÊ∞¥Á∫øËÆæËÆ°ÔºåÊØè‰∏™Èò∂ÊÆµÈÉΩÂèØ‰ª•Áã¨Á´ãÂÆûÁé∞ÂíåÊõøÊç¢„ÄÇ
*   **üîå ÂèØÊâ©Â±ïÊèí‰ª∂Á≥ªÁªü (Extensible Plugin System):** Âü∫‰∫éÂ∑•ÂéÇÊ®°ÂºèÔºåÊÇ®ÂèØ‰ª•ËΩªÊùæÂú∞Ëá™ÂÆö‰πâÈ¢ÑÂ§ÑÁêÜ„ÄÅÊé®ÁêÜÂºïÊìéÂíåÂêéÂ§ÑÁêÜÊèí‰ª∂ÔºåÂπ∂Ê≥®ÂÜåÂà∞Ê°ÜÊû∂‰∏≠„ÄÇ
*   **üîí Á±ªÂûãÂÆâÂÖ®ÁöÑÊï∞ÊçÆÂ§ÑÁêÜ (Type-Safe Data Handling):** ‰ΩøÁî® `std::variant` ÂíåËá™ÂÆö‰πâÁöÑ `TypedBuffer` Êù•ÁÆ°ÁêÜ‰∏çÂêåÁ±ªÂûãÁöÑÊï∞ÊçÆÂíåÂèÇÊï∞ÔºåÊûÅÂ§ßÂú∞ÊèêÈ´ò‰∫Ü‰ª£Á†ÅÁöÑÂÅ•Â£ÆÊÄßÂíåÂèØÁª¥Êä§ÊÄß„ÄÇ
*   **üöÄ Á°¨‰ª∂ÊäΩË±°‰∏éÂä†ÈÄü (Hardware Abstraction & Acceleration):** ÈÄöËøá `TypedBuffer` Áªü‰∏ÄÁÆ°ÁêÜ CPU Âíå GPU ÂÜÖÂ≠òÔºåÊó†ÁºùÊîØÊåÅÂú®‰∏çÂêåËÆæÂ§áÈó¥ÁöÑÊï∞ÊçÆÊµÅËΩ¨‰∏éËÆ°ÁÆó„ÄÇ
*   **‚ú® ÁÆÄÊ¥ÅÊòìÁî®ÁöÑÈ´òÁ∫ß API (High-Level, Easy-to-Use API):** Êèê‰æõ‰∫Ü `AlgoInference` Á±ª‰Ωú‰∏∫Áªü‰∏ÄÂÖ•Âè£ÔºåÂ∞ÅË£Ö‰∫ÜÂ§çÊùÇÁöÑÂ∫ïÂ±ÇË∞ÉÁî®ÔºåËÆ©ÂºÄÂèëËÄÖÂèØ‰ª•‰∏ìÊ≥®‰∫é‰∏öÂä°ÈÄªËæë„ÄÇ
*   **üîß Áé∞‰ª£ C++ ËÆæËÆ° (Modern C++ Design):** ÂπøÊ≥õÈááÁî® C++17/20 ÁâπÊÄßÔºå‰øùËØÅ‰∫Ü‰ª£Á†ÅÁöÑÈ´òÊÄßËÉΩ„ÄÅÈ´òË¥®ÈáèÂíåÂÆâÂÖ®ÊÄß„ÄÇ


## Ê†∏ÂøÉÊû∂ÊûÑ

AI Core ÁöÑÊ†∏ÂøÉÊòØ‰∏Ä‰∏™Ê∏ÖÊô∞ÁöÑÊï∞ÊçÆÊµÅÁÆ°ÈÅì„ÄÇÊï∞ÊçÆ‰ªéËæìÂÖ• (`AlgoInput`) ÂºÄÂßãÔºåÁªèËøá‰∏ÄÁ≥ªÂàóÂ§ÑÁêÜÊ®°ÂùóÔºåÊúÄÁªàÁîüÊàêÁÆóÊ≥ïËæìÂá∫ (`AlgoOutput`)„ÄÇ

```
+-----------+     +-----------------+     +-----------------+
|           |     |                 |     |                 |
| AlgoInput |---->| Preproc Plugin  |---->|  TensorData (in)|
|           |     | (e.g. FrameProc)|     |                 |
+-----------+     +-----------------+     +-----------------+
                                                   |
                                                   v
                                           +-----------------+
                                           |                 |
                                           | Inference Engine|
                                           | (e.g., TensorRT)|
                                           +-----------------+
                                                    |
                                                    v
+-----------+     +------------------+     +------------------+
|           |     |                  |     |                  |
| AlgoOutput|<----| Postproc Plugin  |<----| TensorData (out) |
|           |     | (e.g. YOLO_DET ) |     |                  |
+-----------+     +------------------+     +------------------+
```
- **Êï∞ÊçÆÂÆπÂô®:** `TensorData` ÊòØÊµÅÊ∞¥Á∫øÂÜÖÈÉ®ÁöÑÊ†∏ÂøÉÊï∞ÊçÆÁªìÊûÑÔºåÁî®‰∫éÂú®ÂêÑ‰∏™Èò∂ÊÆµ‰πãÈó¥‰º†ÈÄíÂº†ÈáèÊï∞ÊçÆ„ÄÇ
- **Êèí‰ª∂:** ÊØè‰∏™Â§ÑÁêÜÈò∂ÊÆµÔºàÈ¢ÑÂ§ÑÁêÜ„ÄÅÊé®ÁêÜ„ÄÅÂêéÂ§ÑÁêÜÔºâÈÉΩÊòØ‰∏Ä‰∏™ÂèØÊèíÊãîÁöÑÊèí‰ª∂ÔºåÈÄöËøáÂ≠óÁ¨¶‰∏≤ÂêçÁß∞Âú®ËøêË°åÊó∂Âä®ÊÄÅÂä†ËΩΩ„ÄÇ

## Âø´ÈÄüÂºÄÂßã

### ÁéØÂ¢ÉË¶ÅÊ±Ç

- C++20 ÂÖºÂÆπÁöÑÁºñËØëÂô® (GCC 11+)
- CMake 3.15+
- (ÂèØÈÄâ) CUDA Toolkit 11.x+
- (ÂèØÈÄâ) OpenCV 4.x+


### ÁºñËØë‰∏éÂÆâË£Ö

1.  **Clone the repository:**
    ```bash
    git clone --recurse-submodules https://github.com/sinterwong/ai-core.git
    cd ai-core
    mkdir -p 3rdparty/target/
    curl -L https://github.com/sinterwong/ai-core/releases/download/v1.1.1-alpha/dependency-Linux_x86_64.tgz -o dependency.tgz
    tar -xzf dependency.tgz -C 3rdparty/target/
    ```

2.  **Configure with CMake:**
    ```bash
    mkdir build && cd build
    cmake .. -DBUILD_AI_CORE_TESTS=ON -DBUILD_AI_CORE_EXAMPLES=ON -DWITH_ORT_ENGINE=ON -DWITH_NCNN_ENGINE=ON -DWITH_TRT_ENGINE=OFF
    ```
    *   Use `-DWITH_ORT_ENGINE=ON`, `-DWITH_NCNN_ENGINE=ON`, and `-DWITH_TRT_ENGINE=ON` to enable the respective inference engines.

3.  **Build the project:**
    ```bash
    cmake --build .
    ```
    
4. **Install:**
    ```bash
    cmake --install .
    ```

### ‰ΩøÁî®Á§∫‰æã

ÊöÇÊó∂ÂèØ‰ª•ÂèÇËÄÉ**tests**Âíå**examples**ÁõÆÂΩï‰∏≠ÁöÑÂÜÖÂÆπ„ÄÇ

## ÊñáÊ°£

- **[Ê°ÜÊû∂ËÆæËÆ°‰∏éÊ†∏ÂøÉÊ¶ÇÂøµ](./doc/Framework.md):** Ëß£Êûê AI Core ÁöÑÊû∂ÊûÑËÆæËÆ°„ÄÅÊ†∏ÂøÉÁªÑ‰ª∂ÂíåËÆæËÆ°Âì≤Â≠¶„ÄÇ
- **[API ÂèÇËÄÉÊâãÂÜå](./doc/API.md):** ËØ¶ÁªÜ‰ªãÁªçÊâÄÊúâÂÖ¨ÂºÄÁöÑÁ±ª„ÄÅÂáΩÊï∞ÂíåÊï∞ÊçÆÁ±ªÂûãÔºåÂπ∂Êèê‰æõ‰ΩøÁî®Á§∫‰æã„ÄÇ
- **[Âø´ÈÄüÂÖ•Èó®](./doc/Quickstart.md):** (Âç≥Â∞ÜÊé®Âá∫) ÊâãÊääÊâãÊïôÊÇ®Â¶Ç‰Ωï‰ΩøÁî® AI Core ÂÆåÊï¥Âú∞ÊûÑÂª∫‰∏Ä‰∏™ AI Â∫îÁî®„ÄÇ
